{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Nsmc 데이터 로드\n",
    "train_df = pd.read_csv('./data/ratings_train.csv')\n",
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "train_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '을', '를', '는', '으로']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사 추출 및 불용어 제거하여 데이터 전처리하기\n",
    "# 1. 문서 하나씩 읽어오기 (50개만)\n",
    "# 2. 문서에 okt 형태소 분석 적용 (morphs함수, stem=True 변경)\n",
    "# 3. 불용어 제거\n",
    "# 4. tokenized_words 리스트(문서 별 형태소 추출): [[words, words, words], [words, words, words]]\n",
    "# 5. sentence_nouns 리스트(모든 명사 리스트): [[noun, noun, noun, noun], [noun, noun, noun, noun]]\n",
    "okt = Okt()\n",
    "\n",
    "tokenized_words, sentence_nouns = [] , []\n",
    "\n",
    "for sentence in train_df['document'][:50]:\n",
    "    # 형태소 분석 토큰화\n",
    "    tokenized_word = okt.morphs(sentence, stem=True) # 토큰화 및 정규화 -> 어간을 추출\n",
    "    stopwords_removed_sentence = [word for word in tokenized_word if not word in stopwords]\n",
    "    tokenized_words.append(stopwords_removed_sentence)\n",
    "\n",
    "    # 명사만 추출\n",
    "    nouns = okt.nouns(sentence)\n",
    "    sentence_nouns.append(nouns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 단어 길이 : 60, 가장 짧은 단어 길이 : 1\n",
      "가장 긴 명사 길이 : 29, 가장 짧은 명사 길이 : 1\n"
     ]
    }
   ],
   "source": [
    "# 리뷰의 최대 길이\n",
    "word_len = [len(l) for l in tokenized_words]\n",
    "nouns_len = [len(l) for l in sentence_nouns]\n",
    "\n",
    "print(f\"가장 긴 리뷰 길이 : {max(word_len)}, 가장 짧은 리뷰 길이 : {min(word_len)}\")\n",
    "print(f\"가장 긴 리뷰(명사) 길이 : {max(nouns_len)}, 가장 짧은 리뷰(명사) 길이 : {min(nouns_len)}\")\n",
    "\n",
    "# 가장 긴 리뷰 길이 : 95, 가장 짧은 리뷰 길이 : 1\n",
    "# 가장 긴 리뷰(명사) 길이 : 66, 가장 짧은 리뷰(명사) 길이 : 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec 훈련\n",
    "\n",
    "vector_size = 워드 벡터의 특징 값, 즉 임베딩 된 벡터의 차원  \n",
    "window = 컨텐스트 윈도우 크기  \n",
    "min_count = 단어 최소 빈도 수 제한(빈도가 적은 단어들을 학습하지 않도록 하는 기준)  \n",
    "workers = 학습을 위한 프로세스 수 (workers로 설정을 하거나 혹은 multiprocessing으로 병렬처리)  \n",
    "sg = 0 (CBOW) , 1 (Skip-gram)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec 모델 훈련하기 -> no run\n",
    "model_cbow = Word2Vec(tokenized_words, vector_size=100, window=5, min_count=5, workers=4, sg =0)\n",
    "model_skipgram = Word2Vec(tokenized_words, vector_size=100, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15204, 100)\n",
      "(15204, 100)\n"
     ]
    }
   ],
   "source": [
    "# 완성된 임베딩 매트릭스의 크기 확인(단어수, 차원수) -> no run\n",
    "print(model_cbow.wv.vectors.shape)\n",
    "print(model_skipgram.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장 방법\n",
    "\n",
    "1. 재훈련 없이 모델만 사용\n",
    "2. 재훈련을 할 수 있도록 임베딩에 대한 기본 정보를 함께 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 방법 1 : 재훈련을 하지 않는 경우 \n",
    "## Ram에 로드하지 않고도 디스크나 네트워크에서 데이터를 즉시 읽어 반복할 수 있음\n",
    "## 모델 inference 에서 활용하면 좋음 \n",
    "## -> no run\n",
    "\n",
    "model_cbow.wv.save_word2vec_format('./data/kor_w2v_cbow')\n",
    "model_skipgram.wv.save_word2vec_format('./data/kor_w2v_skipgram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 방법1의 결과를 다시 로드해서 사용\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 모델 불러오기\n",
    "model_cbow_kv = KeyedVectors.load_word2vec_format('./data/kor_w2v_cbow')\n",
    "model_skipgram_kv = KeyedVectors.load_word2vec_format('./data/kor_w2v_skipgram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('설경구', 0.9148017168045044), ('차승원', 0.8984052538871765), ('황정민', 0.8980780839920044), ('안성기', 0.8957299590110779), ('김혜수', 0.8939363360404968)]\n",
      "[('안성기', 0.8880666494369507), ('설경구', 0.8817006349563599), ('최민식', 0.8728572130203247), ('최민수', 0.8718010187149048), ('신들리다', 0.8633845448493958)]\n"
     ]
    }
   ],
   "source": [
    "# 특정 단어를 중심으로 유사한 단어 확인하기\n",
    "\n",
    "print(model_cbow_kv.most_similar(\"한석규\", topn=5))\n",
    "print(model_skipgram_kv.most_similar(\"한석규\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 방법2 : 재훈련 가능한 모델 \n",
    "# -> no run\n",
    "\n",
    "model_cbow.save('./data/kor_w2v_cbow.model')\n",
    "model_skipgram.save('./data/kor_w2v_skipgram.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "## 모델에 vocab 정보 등이 함께 저장된 결과를 로드함\n",
    "\n",
    "model_cbow_model = Word2Vec.load('./data/kor_w2v_cbow.model')\n",
    "model_skipgram_model = Word2Vec.load('./data/kor_w2v_skipgram.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('꼭', 0.6887606978416443), ('강추', 0.6834990382194519), ('후회', 0.6812189221382141), ('강력', 0.602091372013092), ('수고', 0.5819746255874634), ('감상', 0.5753079652786255), ('적극', 0.575278639793396), ('추하다', 0.5751488208770752), ('권하다', 0.5735456943511963), ('소장', 0.570164680480957)]\n",
      "[('강력', 0.7862173914909363), ('강추', 0.7671416997909546), ('적극', 0.7580629587173462), ('권하다', 0.727484941482544), ('추하다', 0.7162095308303833), ('해드리다', 0.7140164375305176), ('보삼', 0.6767366528511047), ('불면증', 0.6703829169273376), ('꼭', 0.6552332043647766), ('예매', 0.647720217704773)]\n"
     ]
    }
   ],
   "source": [
    "# 특정 단어를 중심으로 유사한 단어 확인하기\n",
    "\n",
    "print(model_cbow_model.wv.most_similar('추천'))\n",
    "print(model_skipgram_model.wv.most_similar('추천'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78621733"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 단어 간의 유사도 파악하기\n",
    "model_skipgram_model.wv.similarity('추천', '강력')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('멜로영화', 0.7437077164649963),\n",
       " ('청춘영화', 0.7317690253257751),\n",
       " ('만화영화', 0.7294827103614807),\n",
       " ('공포영화', 0.7282743453979492),\n",
       " ('괴수영화', 0.724732518196106),\n",
       " ('액션영화', 0.7229880094528198),\n",
       " ('판타지영화', 0.7190592288970947),\n",
       " ('애니매이션', 0.7132899761199951),\n",
       " ('공포물', 0.7101417779922485),\n",
       " ('로맨스영화', 0.7087157964706421)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram_model.wv.most_similar(\"영화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('데스노트', 0.8372506499290466),\n",
       " ('초속', 0.8157038688659668),\n",
       " ('4-5', 0.8087527751922607),\n",
       " ('4~5', 0.8024197220802307),\n",
       " ('편임', 0.8012981414794922),\n",
       " ('갓파더', 0.7976078391075134),\n",
       " ('은별', 0.7930920124053955),\n",
       " ('1~4', 0.7910516262054443),\n",
       " ('딥블루씨', 0.7888678908348083),\n",
       " ('어메이징', 0.7884843349456787)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram_model.wv.most_similar(\"인터스텔라\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key '파묘' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 사전에 없는 경우 확인\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_skipgram_model\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49mmost_similar(\u001b[39m\"\u001b[39;49m\u001b[39m파묘\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_lecture/lib/python3.10/site-packages/gensim/models/keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    838\u001b[0m         weight[idx] \u001b[39m=\u001b[39m item[\u001b[39m1\u001b[39m]\n\u001b[1;32m    840\u001b[0m \u001b[39m# compute the weighted average of all keys\u001b[39;00m\n\u001b[0;32m--> 841\u001b[0m mean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_mean_vector(keys, weight, pre_normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, post_normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, ignore_missing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    842\u001b[0m all_keys \u001b[39m=\u001b[39m [\n\u001b[1;32m    843\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_index(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m keys \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, _KEY_TYPES) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_index_for(key)\n\u001b[1;32m    844\u001b[0m ]\n\u001b[1;32m    846\u001b[0m \u001b[39mif\u001b[39;00m indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(topn, \u001b[39mint\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_lecture/lib/python3.10/site-packages/gensim/models/keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m         total_weight \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(weights[idx])\n\u001b[1;32m    517\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_missing:\n\u001b[0;32m--> 518\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present in vocabulary\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[39mif\u001b[39;00m total_weight \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    521\u001b[0m     mean \u001b[39m=\u001b[39m mean \u001b[39m/\u001b[39m total_weight\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key '파묘' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "# 사전에 없는 경우 확인\n",
    "model_skipgram_model.wv.most_similar(\"파묘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('김기덕', 0.626354992389679),\n",
       " ('역량', 0.6012963652610779),\n",
       " ('제작자', 0.5873257517814636),\n",
       " ('장진', 0.5859320163726807),\n",
       " ('박찬욱', 0.5739708542823792),\n",
       " ('자질', 0.5664553642272949),\n",
       " ('작가', 0.5588862895965576),\n",
       " ('오우삼', 0.5537692308425903),\n",
       " ('봉준호', 0.5470575094223022),\n",
       " ('임권택', 0.5425761342048645)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러 단어와 유사한 embedding 가져오기 -> negative: 안 가져옴\n",
    "model_skipgram_model.wv.most_similar(positive=['여자', '감독'], negative=['남자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('김기덕', 0.6410437226295471),\n",
       " ('장진', 0.6115475296974182),\n",
       " ('봉준호', 0.5934121608734131),\n",
       " ('천재', 0.5925087332725525),\n",
       " ('영화감독', 0.5785976648330688),\n",
       " ('핀처', 0.5773937106132507),\n",
       " ('린치', 0.5688480138778687),\n",
       " ('능력', 0.5647576451301575),\n",
       " ('서극', 0.5586300492286682),\n",
       " ('여균동', 0.5543100833892822)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram_model.wv.most_similar(positive=['남자', '감독'], negative=['여자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('연기자', 0.90570467710495),\n",
       " ('배우다', 0.8848891854286194),\n",
       " ('여배우', 0.8822849988937378),\n",
       " ('조연', 0.8544042110443115),\n",
       " ('시나리오', 0.8283987641334534),\n",
       " ('배역', 0.8174970746040344),\n",
       " ('대본', 0.8136961460113525),\n",
       " ('연출', 0.8056817054748535),\n",
       " ('제작비', 0.7905812859535217),\n",
       " ('아이돌', 0.7905701398849487)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기본은 코사인 유사도 => \"cosmul\"\n",
    "model_cbow_model.wv.most_similar_cosmul(positive=['여자', '배우'], negative=['남자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('연기자', 0.9163538813591003),\n",
       " ('조연', 0.8647782206535339),\n",
       " ('배우진', 0.8587888479232788),\n",
       " ('배우다', 0.8470195531845093),\n",
       " ('여배우', 0.8294095993041992),\n",
       " ('배역', 0.8233481645584106),\n",
       " ('엄정화', 0.8203656077384949),\n",
       " ('시나리오', 0.818030595779419),\n",
       " ('송강호', 0.8157493472099304),\n",
       " ('차승원', 0.80646812915802)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow_model.wv.most_similar_cosmul(positive=['남자', '배우'], negative=['여자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6814058\n",
      "0.7202381\n"
     ]
    }
   ],
   "source": [
    "# 그룹간의 유사도 측정\n",
    "print(model_skipgram_model.wv.n_similarity(['남자', '배우'], ['여자', '감독']))\n",
    "print(model_skipgram_model.wv.n_similarity(['남자', '배우'], ['남자', '감독']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감독\n"
     ]
    }
   ],
   "source": [
    "# 가장 유사하지 않은 단어를 추출\n",
    "print(model_skipgram_model.wv.doesnt_match(['영화', '포스터', '감독', '드라마']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음식\n"
     ]
    }
   ],
   "source": [
    "print(model_skipgram_model.wv.doesnt_match(['냉장고', '음식', '밥', '당근']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존에 학습된 모델 확인 및 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300',\n",
      " 'conceptnet-numberbatch-17-06-300',\n",
      " 'word2vec-ruscorpora-300',\n",
      " 'word2vec-google-news-300',\n",
      " 'glove-wiki-gigaword-50',\n",
      " 'glove-wiki-gigaword-100',\n",
      " 'glove-wiki-gigaword-200',\n",
      " 'glove-wiki-gigaword-300',\n",
      " 'glove-twitter-25',\n",
      " 'glove-twitter-50',\n",
      " 'glove-twitter-100',\n",
      " 'glove-twitter-200',\n",
      " '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from pprint import pprint as pp\n",
    "pp(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors_25 = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('facebook', 0.948005199432373),\n",
       " ('tweet', 0.9403423070907593),\n",
       " ('fb', 0.9342359900474548),\n",
       " ('instagram', 0.9104822874069214),\n",
       " ('chat', 0.8964964747428894),\n",
       " ('hashtag', 0.8885936737060547),\n",
       " ('tweets', 0.8878158330917358),\n",
       " ('tl', 0.8778460621833801),\n",
       " ('link', 0.877821147441864),\n",
       " ('internet', 0.8753897547721863)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors_25.most_similar(\"twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('meets', 0.8841923475265503),\n",
       " ('prince', 0.832163393497467),\n",
       " ('queen', 0.8257461190223694),\n",
       " ('’s', 0.817409873008728),\n",
       " ('crow', 0.813499391078949),\n",
       " ('hunter', 0.8131037950515747),\n",
       " ('father', 0.8115834593772888),\n",
       " ('soldier', 0.81113600730896),\n",
       " ('mercy', 0.8082393407821655),\n",
       " ('hero', 0.8082263469696045)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors_25.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors_100 = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('facebook', 0.9159134030342102),\n",
       " ('myspace', 0.8384657502174377),\n",
       " ('youtube', 0.7946597337722778),\n",
       " ('blog', 0.7410154938697815),\n",
       " ('tweets', 0.726836085319519),\n",
       " ('tumblr', 0.7218026518821716),\n",
       " ('blogging', 0.7101113200187683),\n",
       " ('blogs', 0.6958351731300354),\n",
       " ('instagram', 0.6919254660606384),\n",
       " ('email', 0.6856087446212769)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors_100.most_similar(\"twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380928039551),\n",
       " ('throne', 0.6755736470222473),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534157752991),\n",
       " ('prince', 0.6517035365104675),\n",
       " ('elizabeth', 0.6464517712593079),\n",
       " ('mother', 0.6311717629432678),\n",
       " ('emperor', 0.6106470823287964),\n",
       " ('wife', 0.6098655462265015)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors_100.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.8798074126243591),\n",
       " ('rabbit', 0.7424427270889282),\n",
       " ('cats', 0.732300341129303),\n",
       " ('monkey', 0.7288709878921509),\n",
       " ('pet', 0.7190139889717102),\n",
       " ('dogs', 0.7163873314857483),\n",
       " ('mouse', 0.6915250420570374),\n",
       " ('puppy', 0.6800068616867065),\n",
       " ('rat', 0.6641027331352234),\n",
       " ('spider', 0.6501135230064392)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors_100.similar_by_word(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7066633"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors_100.n_similarity(['sushi', 'shop'],['japanese', 'restaurant'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "305494ec69d5ad97a583cc76e8fd52e450123bc765c435a27726a289dbe2d5e0"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
